{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhtOdxzd1ppr"
      },
      "source": [
        "# Lab 4: Data Imputation using an Autoencoder\n",
        "\n",
        "**Deadline**: Mon, Mar 07, 5:00pm\n",
        "\n",
        "**Late Penalty**:  Any work that is submitted between 0 hour and 24 hours past the deadline will receive a 20% grade deduction. No other late work is accepted. Quercus submission time will be used, not your local computer time. You can submit your labs as many times as you want before the deadline, so please submit often and early.\n",
        "\n",
        "**TA**: Shiva Akbari <shiva.akbari@mail.utoronto.ca>\n",
        "\n",
        "In this lab, you will build and train an autoencoder to impute (or \"fill in\") missing data. \n",
        "\n",
        "We will be using the\n",
        "Adult Data Set provided by the UCI Machine Learning Repository [1], available \n",
        "at https://archive.ics.uci.edu/ml/datasets/adult.\n",
        "The data set contains census record files of adults, including their\n",
        "age, martial status, the type of work they do, and other features. \n",
        "\n",
        "Normally, people use this data set to build a supervised classification\n",
        "model to classify whether a person is a high income earner.\n",
        "We will not use the dataset for this original intended purpose.\n",
        "\n",
        "Instead, we will perform the task of imputing (or \"filling in\") missing values in the dataset. For example,\n",
        "we may be missing one person's martial status, and another person's age, and\n",
        "a third person's level of education. Our model will predict the missing features \n",
        "based on the information that we do have about each person.\n",
        "\n",
        "We will use a variation of a denoising autoencoder to solve this data imputation\n",
        "problem. Our autoencoder will be trained using inputs that have one categorical feature artificially\n",
        "removed, and the goal of the autoencoder is to correctly reconstruct all features,\n",
        "including the one removed from the input.\n",
        "\n",
        "In the process, you are expected to learn to:\n",
        "\n",
        "1. Clean and process continuous and categorical data for machine learning.\n",
        "2. Implement an autoencoder that takes continuous and categorical (one-hot) inputs.\n",
        "3. Tune the hyperparameters of an autoencoder.\n",
        "4. Use baseline models to help interpret model performance.\n",
        "\n",
        "[1] Dua, D. and Karra Taniskidou, E. (2017). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.\n",
        "\n",
        "\n",
        "### What to submit\n",
        "\n",
        "Submit a PDF file containing all your code, outputs, and write-up. You can produce a PDF of your Google Colab file by going to File > Print and then save as PDF. The Colab instructions have more information (.html files are also acceptable).\n",
        "\n",
        "Do not submit any other files produced by your code.\n",
        "\n",
        "Include a link to your colab file in your submission.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        
      ],
      "metadata": {
        "id": "Zple6yIOSoUY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbnrp2ig1pps"
      },
      "source": [
        "## Colab Link\n",
        "\n",
        "Include a link to your Colab file here. If you would like the TA to look at your\n",
        "Colab file in case your solutions are cut off, **please make sure that your Colab\n",
        "file is publicly accessible at the time of submission**.\n",
        "\n",
        "Colab Link: https://colab.research.google.com/drive/151Y5uYgrftHh4Kwp49bfWmpSWuMFFIj-?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "collapsed": true,
        "id": "z3p8N43E1ppt",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.utils.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ROwtHcz1ppx"
      },
      "source": [
        "## Part 0\n",
        "\n",
        "We will be using a package called `pandas` for this assignment. \n",
        "\n",
        "If you are using Colab, `pandas` should already be available.\n",
        "If you are using your own computer,\n",
        "installation instructions for `pandas` are available here: \n",
        "https://pandas.pydata.org/pandas-docs/stable/install.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "collapsed": true,
        "id": "IXQ7BP151ppz",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqXihb4Q1pp2"
      },
      "source": [
        "# Part 1. Data Cleaning [15 pt]\n",
        "\n",
        "The adult.data file is available at `https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data`\n",
        "\n",
        "The function `pd.read_csv` loads the adult.data file into a pandas dataframe.\n",
        "You can read about the pandas documentation for `pd.read_csv` at\n",
        "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EOMItFKn1pp3",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "75c7b4a4-222a-4422-9b1f-c5c338356c8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py:311: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
            "  return func(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "header = ['age', 'work', 'fnlwgt', 'edu', 'yredu', 'marriage', 'occupation',\n",
        " 'relationship', 'race', 'sex', 'capgain', 'caploss', 'workhr', 'country']\n",
        "df = pd.read_csv(\n",
        "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
        "    names=header,\n",
        "    index_col=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62Ot405q1pp5",
        "outputId": "84e849eb-b5f2-49c3-f525-efcfa0c61940",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32561, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ],
      "source": [
        "df.shape # there are 32561 rows (records) in the data frame, and 14 columns (features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tr7YG-QY1pp8"
      },
      "source": [
        "### Part (a) Continuous Features [3 pt]\n",
        "\n",
        "For each of the columns `[\"age\", \"yredu\", \"capgain\", \"caploss\", \"workhr\"]`, report the minimum, maximum, and average value across the dataset. \n",
        "\n",
        "Then, normalize each of the features `[\"age\", \"yredu\", \"capgain\", \"caploss\", \"workhr\"]`\n",
        "so that their values are always between 0 and 1.\n",
        "Make sure that you are actually modifying the dataframe `df`. \n",
        "\n",
        "Like numpy arrays and torch tensors, \n",
        "pandas data frames can be sliced. For example, we can\n",
        "display the first 3 rows of the data frame (3 records) below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "9evSLsSa1pp9",
        "outputId": "1922fd7a-e1ec-4b0b-a047-31d8ccf231d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d5673e1d-4109-4b1c-a7a2-77599983df29\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>work</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>edu</th>\n",
              "      <th>yredu</th>\n",
              "      <th>marriage</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capgain</th>\n",
              "      <th>caploss</th>\n",
              "      <th>workhr</th>\n",
              "      <th>country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>77516</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>83311</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>215646</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5673e1d-4109-4b1c-a7a2-77599983df29')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d5673e1d-4109-4b1c-a7a2-77599983df29 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d5673e1d-4109-4b1c-a7a2-77599983df29');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   age               work  fnlwgt         edu  yredu             marriage  \\\n",
              "0   39          State-gov   77516   Bachelors     13        Never-married   \n",
              "1   50   Self-emp-not-inc   83311   Bachelors     13   Married-civ-spouse   \n",
              "2   38            Private  215646     HS-grad      9             Divorced   \n",
              "\n",
              "           occupation    relationship    race    sex  capgain  caploss  \\\n",
              "0        Adm-clerical   Not-in-family   White   Male     2174        0   \n",
              "1     Exec-managerial         Husband   White   Male        0        0   \n",
              "2   Handlers-cleaners   Not-in-family   White   Male        0        0   \n",
              "\n",
              "   workhr         country  \n",
              "0      40   United-States  \n",
              "1      13   United-States  \n",
              "2      40   United-States  "
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ],
      "source": [
        "df[:3] # show the first 3 records"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBOojI6W1pqA"
      },
      "source": [
        "Alternatively, we can slice based on column names, \n",
        "for example `df[\"race\"]`, `df[\"hr\"]`, or even index multiple columns \n",
        "like below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "4v6pp73A1pqB",
        "outputId": "f5715f43-55cf-496e-860b-2600bcbb23ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5e9da609-f18d-40e3-b20a-0ae9ae800b08\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>yredu</th>\n",
              "      <th>capgain</th>\n",
              "      <th>caploss</th>\n",
              "      <th>workhr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>13</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e9da609-f18d-40e3-b20a-0ae9ae800b08')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5e9da609-f18d-40e3-b20a-0ae9ae800b08 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5e9da609-f18d-40e3-b20a-0ae9ae800b08');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   age  yredu  capgain  caploss  workhr\n",
              "0   39     13     2174        0      40\n",
              "1   50     13        0        0      13\n",
              "2   38      9        0        0      40"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ],
      "source": [
        "subdf = df[[\"age\", \"yredu\", \"capgain\", \"caploss\", \"workhr\"]]\n",
        "subdf[:3] # show the first 3 records"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Nru2P0E1pqD"
      },
      "source": [
        "Numpy works nicely with pandas, like below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXrS6tjp1pqE",
        "outputId": "89b8e74f-8205-44c0-f784-422e4ee012fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2842700"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ],
      "source": [
        "np.sum(subdf[\"caploss\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mv5mbxDM1pqH"
      },
      "source": [
        "Just like numpy arrays, you can modify\n",
        "entire columns of data rather than one scalar element at a time.\n",
        "For example, the code  \n",
        "\n",
        "`df[\"age\"] = df[\"age\"] + 1` \n",
        "\n",
        "would increment everyone's age by 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "collapsed": true,
        "id": "k5rlWD7-1pqH",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "0ea7f376-db73-4ea4-b4b9-d288860a732d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4758121f-e2f8-4c76-8c7e-e3f983071541\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>yredu</th>\n",
              "      <th>capgain</th>\n",
              "      <th>caploss</th>\n",
              "      <th>workhr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>38.581647</td>\n",
              "      <td>10.080679</td>\n",
              "      <td>1077.648844</td>\n",
              "      <td>87.30383</td>\n",
              "      <td>40.437456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>90.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>99999.000000</td>\n",
              "      <td>4356.00000</td>\n",
              "      <td>99.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4758121f-e2f8-4c76-8c7e-e3f983071541')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4758121f-e2f8-4c76-8c7e-e3f983071541 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4758121f-e2f8-4c76-8c7e-e3f983071541');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            age      yredu       capgain     caploss     workhr\n",
              "mean  38.581647  10.080679   1077.648844    87.30383  40.437456\n",
              "max   90.000000  16.000000  99999.000000  4356.00000  99.000000\n",
              "min   17.000000   1.000000      0.000000     0.00000   1.000000"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ],
      "source": [
        "#we will use describe to find the min, max and avg of the selected columns\n",
        "subdf.describe().loc[['mean','max','min']]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we use a for loop for normalisation\n",
        "\n",
        "for column in subdf.columns:\n",
        "  df[column] = (df[column]-(df[column]).min()) / ((df[column]).max() - (df[column]).min()) #using the formula\n",
        "\n",
        "df[[\"age\", \"yredu\", \"capgain\", \"caploss\", \"workhr\"]].describe().loc[['mean','max','min']] #visualise changes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "FZSLdlW6X_VZ",
        "outputId": "556ad353-3259-4e05-e67e-38d69df04644"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8a544cb0-cc9e-4ad0-9b49-bbcda2f37dfe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>yredu</th>\n",
              "      <th>capgain</th>\n",
              "      <th>caploss</th>\n",
              "      <th>workhr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.295639</td>\n",
              "      <td>0.605379</td>\n",
              "      <td>0.010777</td>\n",
              "      <td>0.020042</td>\n",
              "      <td>0.402423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a544cb0-cc9e-4ad0-9b49-bbcda2f37dfe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8a544cb0-cc9e-4ad0-9b49-bbcda2f37dfe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8a544cb0-cc9e-4ad0-9b49-bbcda2f37dfe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           age     yredu   capgain   caploss    workhr\n",
              "mean  0.295639  0.605379  0.010777  0.020042  0.402423\n",
              "max   1.000000  1.000000  1.000000  1.000000  1.000000\n",
              "min   0.000000  0.000000  0.000000  0.000000  0.000000"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbfMly4R1pqK"
      },
      "source": [
        "### Part (b) Categorical Features [1 pt]\n",
        "\n",
        "What percentage of people in our data set are male? Note that the data labels all have an unfortunate space in the beginning, e.g. \" Male\" instead of \"Male\".\n",
        "\n",
        "What percentage of people in our data set are female?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjAjcsB_1pqK",
        "outputId": "ca41440c-8b60-4a9a-c694-18ae3b3b8c23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of males is 66.92%\n",
            "Percentage of females is 33.08%\n"
          ]
        }
      ],
      "source": [
        "# hint: you can do something like this in pandas\n",
        "percentage_males = sum(df[\"sex\"] == \" Male\") * 100/len(df)\n",
        "print(f\"Percentage of males is {percentage_males:.2f}%\")\n",
        "\n",
        "percentage_females = sum(df[\"sex\"] == \" Female\") * 100/len(df)\n",
        "print(f\"Percentage of females is {percentage_females:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGVw7pqL1pqN"
      },
      "source": [
        "### Part (c) [2 pt]\n",
        "\n",
        "Before proceeding, we will modify our data frame in a couple more ways:\n",
        "\n",
        "1. We will restrict ourselves to using a subset of the features (to simplify our autoencoder)\n",
        "2. We will remove any records (rows) already containing missing values, and store them in a second dataframe. We will only use records without missing values to train our autoencoder.\n",
        "\n",
        "Both of these steps are done for you, below.\n",
        "\n",
        "How many records contained missing features? What percentage of records were removed?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "collapsed": true,
        "id": "z6ewPUdv1pqO",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "contcols = [\"age\", \"yredu\", \"capgain\", \"caploss\", \"workhr\"]\n",
        "catcols = [\"work\", \"marriage\", \"occupation\", \"edu\", \"relationship\", \"sex\"]\n",
        "features = contcols + catcols\n",
        "df = df[features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "collapsed": true,
        "id": "fjdVll5a1pqQ",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "missing = pd.concat([df[c] == \" ?\" for c in catcols], axis=1).any(axis=1)\n",
        "df_with_missing = df[missing]\n",
        "df_not_missing = df[~missing]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{len(df_with_missing)} records were missing features\")\n",
        "print (f\"{len(df_with_missing)/len(df):.2f}% of records were removed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usBoz5-BZpZU",
        "outputId": "919b2524-edc7-411a-ede2-db7e44807cea"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1843 records were missing features\n",
            "0.06% of records were removed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuEpndTQ1pqU"
      },
      "source": [
        "### Part (d) One-Hot Encoding [1 pt]\n",
        "\n",
        "What are all the possible values of the feature \"work\" in `df_not_missing`? You may find the Python function `set` useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iKFh4owE1pqV",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "77c28a68-0513-456d-f7ac-0dc86f0ab74a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' Self-emp-not-inc', ' State-gov', ' Local-gov', ' Federal-gov', ' Private', ' Without-pay', ' Self-emp-inc'}  are the 'work' features in df_not_missing\n"
          ]
        }
      ],
      "source": [
        "print(set(df_not_missing[\"work\"]), \" are the 'work' features in df_not_missing\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COv3HaKr1pqY"
      },
      "source": [
        "We will be using a one-hot encoding to represent each of the categorical variables.\n",
        "Our autoencoder will be trained using these one-hot encodings.\n",
        "\n",
        "We will use the pandas function `get_dummies` to produce one-hot encodings\n",
        "for all of the categorical variables in `df_not_missing`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "collapsed": true,
        "id": "eKlSYmJg1pqZ",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "data = pd.get_dummies(df_not_missing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "collapsed": true,
        "id": "3y7nTZ7H1pqb",
        "jupyter": {
          "outputs_hidden": true
        },
        "scrolled": true,
        "outputId": "9867cc34-4c54-4f71-daf0-3c759ec1aac2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b688a45b-b794-45df-a11a-9daeb5f44eee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>yredu</th>\n",
              "      <th>capgain</th>\n",
              "      <th>caploss</th>\n",
              "      <th>workhr</th>\n",
              "      <th>work_ Federal-gov</th>\n",
              "      <th>work_ Local-gov</th>\n",
              "      <th>work_ Private</th>\n",
              "      <th>work_ Self-emp-inc</th>\n",
              "      <th>work_ Self-emp-not-inc</th>\n",
              "      <th>...</th>\n",
              "      <th>edu_ Prof-school</th>\n",
              "      <th>edu_ Some-college</th>\n",
              "      <th>relationship_ Husband</th>\n",
              "      <th>relationship_ Not-in-family</th>\n",
              "      <th>relationship_ Other-relative</th>\n",
              "      <th>relationship_ Own-child</th>\n",
              "      <th>relationship_ Unmarried</th>\n",
              "      <th>relationship_ Wife</th>\n",
              "      <th>sex_ Female</th>\n",
              "      <th>sex_ Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.301370</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.02174</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.397959</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.452055</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.122449</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.287671</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.397959</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 57 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b688a45b-b794-45df-a11a-9daeb5f44eee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b688a45b-b794-45df-a11a-9daeb5f44eee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b688a45b-b794-45df-a11a-9daeb5f44eee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        age     yredu  capgain  caploss    workhr  work_ Federal-gov  \\\n",
              "0  0.301370  0.800000  0.02174      0.0  0.397959                  0   \n",
              "1  0.452055  0.800000  0.00000      0.0  0.122449                  0   \n",
              "2  0.287671  0.533333  0.00000      0.0  0.397959                  0   \n",
              "\n",
              "   work_ Local-gov  work_ Private  work_ Self-emp-inc  work_ Self-emp-not-inc  \\\n",
              "0                0              0                   0                       0   \n",
              "1                0              0                   0                       1   \n",
              "2                0              1                   0                       0   \n",
              "\n",
              "   ...  edu_ Prof-school  edu_ Some-college  relationship_ Husband  \\\n",
              "0  ...                 0                  0                      0   \n",
              "1  ...                 0                  0                      1   \n",
              "2  ...                 0                  0                      0   \n",
              "\n",
              "   relationship_ Not-in-family  relationship_ Other-relative  \\\n",
              "0                            1                             0   \n",
              "1                            0                             0   \n",
              "2                            1                             0   \n",
              "\n",
              "   relationship_ Own-child  relationship_ Unmarried  relationship_ Wife  \\\n",
              "0                        0                        0                   0   \n",
              "1                        0                        0                   0   \n",
              "2                        0                        0                   0   \n",
              "\n",
              "   sex_ Female  sex_ Male  \n",
              "0            0          1  \n",
              "1            0          1  \n",
              "2            0          1  \n",
              "\n",
              "[3 rows x 57 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ],
      "source": [
        "data[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwjDg1uM1pqe"
      },
      "source": [
        "### Part (e) One-Hot Encoding [2 pt]\n",
        "\n",
        "The dataframe `data` contains the cleaned and normalized data that we will use to train our denoising autoencoder.\n",
        "\n",
        "How many **columns** (features) are in the dataframe `data`?\n",
        "\n",
        "Briefly explain where that number come from."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yjZ5N0Tl1pqf",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "167c5a61-edfc-4597-a273-b70fae774613"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57\n"
          ]
        }
      ],
      "source": [
        "print(len(data.columns))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Data` dataframe contains 57 columns. These come from the one-hot encodings of all the possible values of the categorical categories. This allows us to represent whether the person belongs to a specific categorical variable in a binary manner. 57 means that there are a total of 57 categorical descriptors in the dataset. "
      ],
      "metadata": {
        "id": "3UqSAJvwcF-4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEJ0Ci3l1pqh"
      },
      "source": [
        "### Part (f) One-Hot Conversion [3 pt]\n",
        "\n",
        "We will convert the pandas data frame `data` into numpy, so that\n",
        "it can be further converted into a PyTorch tensor.\n",
        "However, in doing so, we lose the column label information that\n",
        "a panda data frame automatically stores.\n",
        "\n",
        "Complete the function `get_categorical_value` that will return\n",
        "the named value of a feature given a one-hot embedding.\n",
        "You may find the global variables `cat_index` and `cat_values`\n",
        "useful. (Display them and figure out what they are first.)\n",
        "\n",
        "We will need this function in the next part of the lab\n",
        "to interpret our autoencoder outputs. So, the input\n",
        "to our function `get_categorical_values` might not \n",
        "actually be \"one-hot\" -- the input may instead \n",
        "contain real-valued predictions from our neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "collapsed": true,
        "id": "ZmovX6gu1pqi",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "datanp = data.values.astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "collapsed": true,
        "id": "YRIa5MBd1pql",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "cat_index = {}  # Mapping of feature -> start index of feature in a record\n",
        "cat_values = {} # Mapping of feature -> list of categorical values the feature can take\n",
        "\n",
        "# build up the cat_index and cat_values dictionary\n",
        "for i, header in enumerate(data.keys()):\n",
        "    if \"_\" in header: # categorical header\n",
        "        feature, value = header.split()\n",
        "        feature = feature[:-1] # remove the last char; it is always an underscore\n",
        "        if feature not in cat_index:\n",
        "            cat_index[feature] = i\n",
        "            cat_values[feature] = [value]\n",
        "        else:\n",
        "            cat_values[feature].append(value)\n",
        "\n",
        "def get_onehot(record, feature):\n",
        "    \"\"\"\n",
        "    Return the portion of `record` that is the one-hot encoding\n",
        "    of `feature`. For example, since the feature \"work\" is stored\n",
        "    in the indices [5:12] in each record, calling `get_range(record, \"work\")`\n",
        "    is equivalent to accessing `record[5:12]`.\n",
        "    \n",
        "    Args:\n",
        "        - record: a numpy array representing one record, formatted\n",
        "                  the same way as a row in `data.np`\n",
        "        - feature: a string, should be an element of `catcols`\n",
        "    \"\"\"\n",
        "    start_index = cat_index[feature]\n",
        "    stop_index = cat_index[feature] + len(cat_values[feature])\n",
        "    return record[start_index:stop_index]\n",
        "\n",
        "def get_categorical_value(onehot, feature):\n",
        "    \"\"\"\n",
        "    Return the categorical value name of a feature given\n",
        "    a one-hot vector representing the feature.\n",
        "    \n",
        "    Args:\n",
        "        - onehot: a numpy array one-hot representation of the feature\n",
        "        - feature: a string, should be an element of `catcols`\n",
        "        \n",
        "    Examples:\n",
        "    \n",
        "    >>> get_categorical_value(np.array([0., 0., 0., 0., 0., 1., 0.]), \"work\")\n",
        "    'State-gov'\n",
        "    >>> get_categorical_value(np.array([0.1, 0., 1.1, 0.2, 0., 1., 0.]), \"work\")\n",
        "    'Private'\n",
        "    \"\"\"\n",
        "    # <----- TODO: WRITE YOUR CODE HERE ----->\n",
        "    # You may find the variables `cat_index` and `cat_values` \n",
        "    # (created above) useful.\n",
        "    return cat_values[feature][np.argmax(onehot)] \n",
        "    #since we have to return the categorical value name with the highest prediction confidence, \n",
        "    #we use np.argmax to get the index of that feature to look in cat_values dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "collapsed": true,
        "id": "T_XXxZdh1pqv",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# more useful code, used during training, that depends on the function\n",
        "# you write above\n",
        "\n",
        "def get_feature(record, feature):\n",
        "    \"\"\"\n",
        "    Return the categorical feature value of a record\n",
        "    \"\"\"\n",
        "    onehot = get_onehot(record, feature)\n",
        "    return get_categorical_value(onehot, feature)\n",
        "\n",
        "def get_features(record):\n",
        "    \"\"\"\n",
        "    Return a dictionary of all categorical feature values of a record\n",
        "    \"\"\"\n",
        "    return { f: get_feature(record, f) for f in catcols }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_5ZZR_J1pqy"
      },
      "source": [
        "### Part (g) Train/Test Split [3 pt]\n",
        "\n",
        "Randomly split the data into approximately 70% training, 15% validation and 15% test.\n",
        "\n",
        "Report the number of items in your training, validation, and test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TE_fTJJf1pqz",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "e92dddf1-e825-4ae2-b823-510d6151b939"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of training data is 21502, length of val data is 4608, and length of test data is 4608.\n"
          ]
        }
      ],
      "source": [
        "# set the numpy seed for reproducibility\n",
        "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.seed.html\n",
        "np.random.seed(50)\n",
        "\n",
        "# todo\n",
        "np.random.shuffle(datanp)\n",
        "total_data = len(datanp)\n",
        "train_data, val_data, test_data = datanp[:int(0.7*total_data)], datanp[int(0.7*total_data):int(0.85*total_data)], datanp[int(0.85*total_data):]\n",
        "print(f\"Length of training data is {len(train_data)}, length of val data is {len(val_data)}, and length of test data is {len(test_data)}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9wJAKOI1pq3"
      },
      "source": [
        "## Part 2. Model Setup [5 pt]\n",
        "\n",
        "### Part (a) [4 pt]\n",
        "\n",
        "Design a fully-connected autoencoder by modifying the `encoder` and `decoder`\n",
        "below.\n",
        "\n",
        "The input to this autoencoder will be the features of the `data`, with\n",
        "one categorical feature recorded as \"missing\". The output of the autoencoder\n",
        "should be the reconstruction of the same features, but with the missing\n",
        "value filled in.\n",
        "\n",
        "**Note**: Do not reduce the dimensionality of the input too much!\n",
        "The output of your embedding is expected to contain information \n",
        "about ~11 features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "collapsed": true,
        "id": "f3F--tdn1pq3",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        self.name = \"AutoEncoder\"\n",
        "\n",
        "        super(AutoEncoder, self).__init__()\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(57, 28), \n",
        "            nn.ReLU(),\n",
        "            nn.Linear(28,14),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(14,28),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(28,57),\n",
        "            nn.Sigmoid() # get to the range (0, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuEzTSAv1pq6"
      },
      "source": [
        "### Part (b) [1 pt]\n",
        "\n",
        "Explain why there is a sigmoid activation in the last step of the decoder.\n",
        "\n",
        "(**Note**: the values inside the data frame `data` and the training code in Part 3 might be helpful.)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data in the columns for the categorical one-hot encoded values are between 0 and 1 due to the normalization performed earlier, by using sigmoid, we force the output to be between 0 and 1 as well, therefore the output would match the autoencoder input data type. \n",
        "\n"
      ],
      "metadata": {
        "id": "fG4si6vxjCVk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYwqFWVl1pq8"
      },
      "source": [
        "## Part 3. Training [18] \n",
        "\n",
        "### Part (a) [6 pt]\n",
        "\n",
        "We will train our autoencoder in the following way:\n",
        "\n",
        "- In each iteration, we will hide one of the categorical features using the `zero_out_random_features` function\n",
        "- We will pass the data with one missing feature through the autoencoder, and obtain a reconstruction\n",
        "- We will check how close the reconstruction is compared to the original data -- including the value of the missing feature\n",
        "\n",
        "Complete the code to train the autoencoder, and plot the training and validation loss every few iterations.\n",
        "You may also want to plot training and validation \"accuracy\" every few iterations, as we will define in\n",
        "part (b). You may also want to checkpoint your model every few iterations or epochs.\n",
        "\n",
        "Use `nn.MSELoss()` as your loss function. (Side note: you might recognize that this loss function is not\n",
        "ideal for this problem, but we will use it anyway.)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRB7PZVgqF8d",
        "outputId": "6980d684-64a2-479a-b672-7e6d85bdbd05"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "collapsed": true,
        "id": "IDQA_-dS1pq9",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def zero_out_feature(records, feature):\n",
        "    \"\"\" Set the feature missing in records, by setting the appropriate\n",
        "    columns of records to 0\n",
        "    \"\"\"\n",
        "    start_index = cat_index[feature]\n",
        "    stop_index = cat_index[feature] + len(cat_values[feature])\n",
        "    records[:, start_index:stop_index] = 0\n",
        "    return records\n",
        "\n",
        "def zero_out_random_feature(records):\n",
        "    \"\"\" Set one random feature missing in records, by setting the \n",
        "    appropriate columns of records to 0\n",
        "    \"\"\"\n",
        "    return zero_out_feature(records, random.choice(catcols))\n",
        "\n",
        "def train(model, train_data, val_data, batch_size, num_epochs=5, learning_rate=1e-4, plot = True):\n",
        "    \"\"\" Training loop. You should update this.\"\"\"\n",
        "    \n",
        "    train_loader= torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
        "    val_loader= torch.utils.data.DataLoader(val_data, batch_size= batch_size, shuffle = True)\n",
        "    model = model.to(device)\n",
        "    torch.manual_seed(42)\n",
        "    criterion = nn.MSELoss().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5, verbose= True, min_lr=1e-6)\n",
        "\n",
        "    iters, losses, val_losses, acc, val_acc = [], [], [], [], []\n",
        "    model_path = f\"model_{model.name}_bs{batch_size}_lr{learning_rate}_epochs{num_epochs}\"\n",
        "    os.makedirs(os.path.join(\"/content/backup\",model_path), exist_ok = True)\n",
        "    model.train()        \n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss_per_epoch, train_batches, val_loss_per_epoch, val_batches = 0.0, 0.0, 0.0, 0.0\n",
        "        for data in train_loader:\n",
        "            data = data.to(device)\n",
        "            datam = zero_out_random_feature(data.clone()).to(device) # zero out one categorical feature\n",
        "            recon = model(datam)\n",
        "            loss = criterion(recon, data)\n",
        "            train_loss_per_epoch += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            train_batches +=1\n",
        "\n",
        "        for data_val in val_loader:\n",
        "            data_val = data_val.to(device)\n",
        "            datam_val = zero_out_random_feature(data_val.clone()).to(device) # zero out one categorical feature\n",
        "            recon_val = model(datam_val)\n",
        "            val_loss = criterion(recon_val, data_val)\n",
        "            val_loss_per_epoch += val_loss.item()\n",
        "            val_batches +=1\n",
        "\n",
        "        iters.append(epoch)\n",
        "        losses.append(float(train_loss_per_epoch)/train_batches) # compute training loss\n",
        "        acc.append(get_accuracy(model, train_loader)) # compute training accuracy\n",
        "        val_losses.append(float(val_loss_per_epoch)/val_batches) # compute val loss\n",
        "        val_acc.append(get_accuracy(model, val_loader))  # compute validation accuracy\n",
        "        scheduler.step(val_acc[-1])\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}: Training loss {losses[-1]:.3f} , Val loss {val_losses[-1]:.3f} , Training accuracy {acc[-1]:.3f} , Val accuracy {val_acc[-1]:.3f}\")\n",
        "        if val_acc[-1]==max(val_acc):\n",
        "            torch.save(model.state_dict(), os.path.join(\"/content/backup\", model_path, \"best.pth\"))\n",
        "            print (\"best model saved\")\n",
        "        if epoch % 10 == 0:\n",
        "            torch.save(model.state_dict(), os.path.join(\"/content/backup\", model_path, f\"{epoch}.pth\"))\n",
        "            print (\"checkpoint model saved\")\n",
        "\n",
        "    print (f\"Best training accuracy is {max(acc)}\")\n",
        "    print (f\"Best val accuracy is {max(val_acc)}\")\n",
        "    if plot: # plotting\n",
        "      plt.title(\"Loss Curve\")\n",
        "      plt.plot(iters, losses, label=\"Train\")\n",
        "      plt.plot(iters, val_losses, label=\"Validation\")\n",
        "      plt.xlabel(\"Iterations\")\n",
        "      plt.ylabel(\"Loss\")\n",
        "      plt.legend(loc='best')\n",
        "      plt.show()\n",
        "\n",
        "      plt.title(\"Accuracy Curve\")\n",
        "      plt.plot(iters, acc, label=\"Train\")\n",
        "      plt.plot(iters, val_acc, label=\"Validation\")\n",
        "      plt.xlabel(\"Iterations\")\n",
        "      plt.ylabel(\"Accuracy\")\n",
        "      plt.legend(loc='best')\n",
        "      plt.show()       "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKk01pwx1pq_"
      },
      "source": [
        "### Part (b) [3 pt]\n",
        "\n",
        "While plotting training and validation loss is valuable, loss values are harder to compare\n",
        "than accuracy percentages. It would be nice to have a measure of \"accuracy\" in this problem.\n",
        "\n",
        "Since we will only be imputing missing categorical values, we will define an accuracy measure.\n",
        "For each record and for each categorical feature, we determine whether\n",
        "the model can predict the categorical feature given all the other features of the record.\n",
        "\n",
        "A function `get_accuracy` is written for you. It is up to you to figure out how to\n",
        "use the function. **You don't need to submit anything in this part.**\n",
        "To earn the marks, correctly plot the training and validation accuracy every few \n",
        "iterations as part of your training curve."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "collapsed": true,
        "id": "bHWLfCzM1pq_",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "def get_accuracy(model, data_loader):\n",
        "    \"\"\"Return the \"accuracy\" of the autoencoder model across a data set.\n",
        "    That is, for each record and for each categorical feature, \n",
        "    we determine whether the model can successfully predict the value\n",
        "    of the categorical feature given all the other features of the \n",
        "    record. The returned \"accuracy\" measure is the percentage of times \n",
        "    that our model is successful.\n",
        "        \n",
        "    Args:\n",
        "       - model: the autoencoder model, an instance of nn.Module\n",
        "       - data_loader: an instance of torch.utils.data.DataLoader\n",
        "\n",
        "    Example (to illustrate how get_accuracy is intended to be called.\n",
        "             Depending on your variable naming this code might require\n",
        "             modification.)\n",
        "\n",
        "        >>> model = AutoEncoder()\n",
        "        >>> vdl = torch.utils.data.DataLoader(data_valid, batch_size=256, shuffle=True)\n",
        "        >>> get_accuracy(model, vdl)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    acc = 0\n",
        "    model = model.to(\"cpu\")\n",
        "    for col in catcols:\n",
        "        for item in data_loader: # minibatches\n",
        "            inp = item.detach().numpy()\n",
        "            out = model(zero_out_feature(item.clone(), col)).detach().numpy()\n",
        "            for i in range(out.shape[0]): # record in minibatch\n",
        "                acc += int(get_feature(out[i], col) == get_feature(inp[i], col))\n",
        "                total += 1\n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "    return acc / total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxCTlXoV1prB"
      },
      "source": [
        "### Part (c) [4 pt]\n",
        "\n",
        "Run your updated training code, using reasonable initial hyperparameters.\n",
        "\n",
        "Include your training curve in your submission."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "nj5b71l-1prC",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "8a360130-0b11-4671-f6b6-999fd5619acd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50: Training loss 0.072 , Val loss 0.047 , Training accuracy 0.577 , Val accuracy 0.578\n",
            "best model saved\n",
            "checkpoint model saved\n",
            "Epoch 2/50: Training loss 0.038 , Val loss 0.034 , Training accuracy 0.601 , Val accuracy 0.599\n",
            "best model saved\n",
            "Epoch 3/50: Training loss 0.031 , Val loss 0.029 , Training accuracy 0.604 , Val accuracy 0.602\n",
            "best model saved\n",
            "Epoch 4/50: Training loss 0.027 , Val loss 0.027 , Training accuracy 0.597 , Val accuracy 0.599\n",
            "Epoch     5: reducing learning rate of group 0 to 5.0000e-04.\n",
            "Epoch 5/50: Training loss 0.025 , Val loss 0.024 , Training accuracy 0.598 , Val accuracy 0.601\n",
            "Epoch 6/50: Training loss 0.023 , Val loss 0.023 , Training accuracy 0.595 , Val accuracy 0.594\n",
            "Epoch 7/50: Training loss 0.022 , Val loss 0.022 , Training accuracy 0.609 , Val accuracy 0.609\n",
            "best model saved\n",
            "Epoch 8/50: Training loss 0.021 , Val loss 0.021 , Training accuracy 0.603 , Val accuracy 0.601\n",
            "Epoch     9: reducing learning rate of group 0 to 2.5000e-04.\n",
            "Epoch 9/50: Training loss 0.021 , Val loss 0.020 , Training accuracy 0.604 , Val accuracy 0.604\n",
            "Epoch 10/50: Training loss 0.020 , Val loss 0.020 , Training accuracy 0.603 , Val accuracy 0.604\n",
            "Epoch 11/50: Training loss 0.020 , Val loss 0.020 , Training accuracy 0.602 , Val accuracy 0.603\n",
            "checkpoint model saved\n",
            "Epoch 12/50: Training loss 0.020 , Val loss 0.020 , Training accuracy 0.609 , Val accuracy 0.609\n",
            "best model saved\n",
            "Epoch    13: reducing learning rate of group 0 to 1.2500e-04.\n",
            "Epoch 13/50: Training loss 0.019 , Val loss 0.019 , Training accuracy 0.607 , Val accuracy 0.606\n",
            "Epoch 14/50: Training loss 0.019 , Val loss 0.019 , Training accuracy 0.609 , Val accuracy 0.609\n",
            "Epoch 15/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.608 , Val accuracy 0.607\n",
            "Epoch 16/50: Training loss 0.018 , Val loss 0.019 , Training accuracy 0.606 , Val accuracy 0.606\n",
            "Epoch    17: reducing learning rate of group 0 to 6.2500e-05.\n",
            "Epoch 17/50: Training loss 0.019 , Val loss 0.018 , Training accuracy 0.609 , Val accuracy 0.610\n",
            "best model saved\n",
            "Epoch 18/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.610 , Val accuracy 0.611\n",
            "best model saved\n",
            "Epoch 19/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.611 , Val accuracy 0.611\n",
            "best model saved\n",
            "Epoch 20/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.613 , Val accuracy 0.612\n",
            "best model saved\n",
            "Epoch    21: reducing learning rate of group 0 to 3.1250e-05.\n",
            "Epoch 21/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.613 , Val accuracy 0.614\n",
            "best model saved\n",
            "checkpoint model saved\n",
            "Epoch 22/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.611 , Val accuracy 0.612\n",
            "Epoch 23/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.611 , Val accuracy 0.612\n",
            "Epoch 24/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.613 , Val accuracy 0.614\n",
            "best model saved\n",
            "Epoch    25: reducing learning rate of group 0 to 1.5625e-05.\n",
            "Epoch 25/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.611 , Val accuracy 0.612\n",
            "Epoch 26/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.612 , Val accuracy 0.613\n",
            "Epoch 27/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.612 , Val accuracy 0.613\n",
            "Epoch 28/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.612 , Val accuracy 0.611\n",
            "Epoch    29: reducing learning rate of group 0 to 7.8125e-06.\n",
            "Epoch 29/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.612 , Val accuracy 0.612\n",
            "Epoch 30/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.612 , Val accuracy 0.612\n",
            "Epoch 31/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.612 , Val accuracy 0.612\n",
            "checkpoint model saved\n",
            "Epoch 32/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.612 , Val accuracy 0.612\n",
            "Epoch    33: reducing learning rate of group 0 to 3.9063e-06.\n",
            "Epoch 33/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.612 , Val accuracy 0.612\n",
            "Epoch 34/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.612 , Val accuracy 0.612\n",
            "Epoch 35/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.612 , Val accuracy 0.612\n",
            "Epoch 36/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.612 , Val accuracy 0.612\n",
            "Epoch    37: reducing learning rate of group 0 to 1.9531e-06.\n",
            "Epoch 37/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.612 , Val accuracy 0.612\n",
            "Epoch 38/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.612 , Val accuracy 0.611\n",
            "Epoch 39/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.612 , Val accuracy 0.611\n",
            "Epoch 40/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.612 , Val accuracy 0.612\n",
            "Epoch    41: reducing learning rate of group 0 to 1.0000e-06.\n",
            "Epoch 41/50: Training loss 0.018 , Val loss 0.019 , Training accuracy 0.612 , Val accuracy 0.612\n",
            "checkpoint model saved\n",
            "Epoch 42/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.612 , Val accuracy 0.612\n",
            "Epoch 43/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.612 , Val accuracy 0.612\n",
            "Epoch 44/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.612 , Val accuracy 0.612\n",
            "Epoch 45/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.612 , Val accuracy 0.612\n",
            "Epoch 46/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.612 , Val accuracy 0.612\n",
            "Epoch 47/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.612 , Val accuracy 0.612\n",
            "Epoch 48/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.612 , Val accuracy 0.612\n",
            "Epoch 49/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.612 , Val accuracy 0.612\n",
            "Epoch 50/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.612 , Val accuracy 0.612\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "model = AutoEncoder()\n",
        "batch_size = 32\n",
        "num_epochs = 50\n",
        "learning_rate = 0.001\n",
        "\n",
        "train(model, train_data, val_data, batch_size, num_epochs=num_epochs, learning_rate=learning_rate, plot = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/backup"
      ],
      "metadata": {
        "id": "9xtI2Htr8YTQ"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9xTwIf51prF"
      },
      "source": [
        "### Part (d) [5 pt]\n",
        "\n",
        "Tune your hyperparameters, training at least 4 different models (4 sets of hyperparameters).\n",
        "\n",
        "Do not include all your training curves. Instead, explain what hyperparameters\n",
        "you tried, what their effect was, and what your thought process was as you \n",
        "chose the next set of hyperparameters to try."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main hyperparameter training is related to learning rate and batch size. We can try learning rate to be 0.001 and 0.005, with batch size being 32 and 64. number of epochs is set at 50, as shown above that 50 epochs are enough for model to stabilise.\n",
        "\n",
        "The reason for trying a batch size of 64 and learning rate of 0.005 is to accelerate training, but keep it more generalised training (though the training accuracy and validation acc follow closely, implying that the generalization ability of the model is great)"
      ],
      "metadata": {
        "id": "ZHDKOMtR4fsB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PhTKt9iL1prG",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "d1b61a31-665b-458f-a04a-536a2ff317be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50: Training loss 0.092 , Val loss 0.055 , Training accuracy 0.536 , Val accuracy 0.539\n",
            "best model saved\n",
            "checkpoint model saved\n",
            "Epoch 2/50: Training loss 0.048 , Val loss 0.041 , Training accuracy 0.586 , Val accuracy 0.587\n",
            "best model saved\n",
            "Epoch 3/50: Training loss 0.038 , Val loss 0.035 , Training accuracy 0.611 , Val accuracy 0.607\n",
            "best model saved\n",
            "Epoch 4/50: Training loss 0.032 , Val loss 0.031 , Training accuracy 0.606 , Val accuracy 0.602\n",
            "Epoch     5: reducing learning rate of group 0 to 5.0000e-04.\n",
            "Epoch 5/50: Training loss 0.031 , Val loss 0.030 , Training accuracy 0.613 , Val accuracy 0.612\n",
            "best model saved\n",
            "Epoch 6/50: Training loss 0.029 , Val loss 0.029 , Training accuracy 0.612 , Val accuracy 0.611\n",
            "Epoch 7/50: Training loss 0.028 , Val loss 0.027 , Training accuracy 0.612 , Val accuracy 0.611\n",
            "Epoch 8/50: Training loss 0.026 , Val loss 0.026 , Training accuracy 0.609 , Val accuracy 0.609\n",
            "Epoch     9: reducing learning rate of group 0 to 2.5000e-04.\n",
            "Epoch 9/50: Training loss 0.025 , Val loss 0.025 , Training accuracy 0.607 , Val accuracy 0.610\n",
            "Epoch 10/50: Training loss 0.025 , Val loss 0.025 , Training accuracy 0.609 , Val accuracy 0.612\n",
            "Epoch 11/50: Training loss 0.025 , Val loss 0.024 , Training accuracy 0.610 , Val accuracy 0.612\n",
            "checkpoint model saved\n",
            "Epoch 12/50: Training loss 0.024 , Val loss 0.023 , Training accuracy 0.610 , Val accuracy 0.612\n",
            "best model saved\n",
            "Epoch    13: reducing learning rate of group 0 to 1.2500e-04.\n",
            "Epoch 13/50: Training loss 0.024 , Val loss 0.023 , Training accuracy 0.610 , Val accuracy 0.611\n",
            "Epoch 14/50: Training loss 0.023 , Val loss 0.024 , Training accuracy 0.609 , Val accuracy 0.611\n",
            "Epoch 15/50: Training loss 0.023 , Val loss 0.023 , Training accuracy 0.609 , Val accuracy 0.612\n",
            "Epoch 16/50: Training loss 0.023 , Val loss 0.023 , Training accuracy 0.610 , Val accuracy 0.613\n",
            "best model saved\n",
            "Epoch    17: reducing learning rate of group 0 to 6.2500e-05.\n",
            "Epoch 17/50: Training loss 0.023 , Val loss 0.023 , Training accuracy 0.611 , Val accuracy 0.613\n",
            "best model saved\n",
            "Epoch 18/50: Training loss 0.023 , Val loss 0.023 , Training accuracy 0.610 , Val accuracy 0.612\n",
            "Epoch 19/50: Training loss 0.023 , Val loss 0.023 , Training accuracy 0.612 , Val accuracy 0.613\n",
            "best model saved\n",
            "Epoch 20/50: Training loss 0.023 , Val loss 0.023 , Training accuracy 0.611 , Val accuracy 0.613\n",
            "Epoch    21: reducing learning rate of group 0 to 3.1250e-05.\n",
            "Epoch 21/50: Training loss 0.023 , Val loss 0.023 , Training accuracy 0.611 , Val accuracy 0.613\n",
            "checkpoint model saved\n",
            "Epoch 22/50: Training loss 0.023 , Val loss 0.023 , Training accuracy 0.610 , Val accuracy 0.612\n",
            "Epoch 23/50: Training loss 0.023 , Val loss 0.023 , Training accuracy 0.612 , Val accuracy 0.614\n",
            "best model saved\n",
            "Epoch 24/50: Training loss 0.023 , Val loss 0.023 , Training accuracy 0.611 , Val accuracy 0.613\n",
            "Epoch    25: reducing learning rate of group 0 to 1.5625e-05.\n",
            "Epoch 25/50: Training loss 0.022 , Val loss 0.023 , Training accuracy 0.611 , Val accuracy 0.612\n",
            "Epoch 26/50: Training loss 0.023 , Val loss 0.023 , Training accuracy 0.611 , Val accuracy 0.612\n",
            "Epoch 27/50: Training loss 0.023 , Val loss 0.023 , Training accuracy 0.611 , Val accuracy 0.612\n",
            "Epoch 28/50: Training loss 0.023 , Val loss 0.023 , Training accuracy 0.611 , Val accuracy 0.613\n",
            "Epoch    29: reducing learning rate of group 0 to 7.8125e-06.\n",
            "Epoch 29/50: Training loss 0.023 , Val loss 0.023 , Training accuracy 0.611 , Val accuracy 0.613\n",
            "Epoch 30/50: Training loss 0.023 , Val loss 0.023 , Training accuracy 0.611 , Val accuracy 0.612\n",
            "Epoch 31/50: Training loss 0.022 , Val loss 0.022 , Training accuracy 0.611 , Val accuracy 0.612\n",
            "checkpoint model saved\n",
            "Epoch 32/50: Training loss 0.023 , Val loss 0.022 , Training accuracy 0.611 , Val accuracy 0.612\n",
            "Epoch    33: reducing learning rate of group 0 to 3.9063e-06.\n",
            "Epoch 33/50: Training loss 0.023 , Val loss 0.023 , Training accuracy 0.611 , Val accuracy 0.612\n",
            "Epoch 34/50: Training loss 0.023 , Val loss 0.023 , Training accuracy 0.611 , Val accuracy 0.612\n",
            "Epoch 35/50: Training loss 0.023 , Val loss 0.023 , Training accuracy 0.611 , Val accuracy 0.612\n",
            "Epoch 36/50: Training loss 0.023 , Val loss 0.022 , Training accuracy 0.611 , Val accuracy 0.612\n",
            "Epoch    37: reducing learning rate of group 0 to 1.9531e-06.\n",
            "Epoch 37/50: Training loss 0.022 , Val loss 0.022 , Training accuracy 0.611 , Val accuracy 0.612\n",
            "Epoch 38/50: Training loss 0.023 , Val loss 0.023 , Training accuracy 0.611 , Val accuracy 0.612\n",
            "Epoch 39/50: Training loss 0.023 , Val loss 0.023 , Training accuracy 0.611 , Val accuracy 0.612\n",
            "Epoch 40/50: Training loss 0.023 , Val loss 0.022 , Training accuracy 0.611 , Val accuracy 0.612\n",
            "Epoch    41: reducing learning rate of group 0 to 1.0000e-06.\n",
            "Epoch 41/50: Training loss 0.022 , Val loss 0.022 , Training accuracy 0.611 , Val accuracy 0.612\n",
            "checkpoint model saved\n",
            "Epoch 42/50: Training loss 0.023 , Val loss 0.023 , Training accuracy 0.611 , Val accuracy 0.612\n",
            "Epoch 43/50: Training loss 0.022 , Val loss 0.023 , Training accuracy 0.611 , Val accuracy 0.612\n",
            "Epoch 44/50: Training loss 0.023 , Val loss 0.022 , Training accuracy 0.612 , Val accuracy 0.612\n",
            "Epoch 45/50: Training loss 0.023 , Val loss 0.023 , Training accuracy 0.611 , Val accuracy 0.612\n",
            "Epoch 46/50: Training loss 0.023 , Val loss 0.023 , Training accuracy 0.611 , Val accuracy 0.612\n",
            "Epoch 47/50: Training loss 0.022 , Val loss 0.023 , Training accuracy 0.611 , Val accuracy 0.612\n",
            "Epoch 48/50: Training loss 0.022 , Val loss 0.022 , Training accuracy 0.612 , Val accuracy 0.612\n",
            "Epoch 49/50: Training loss 0.022 , Val loss 0.023 , Training accuracy 0.611 , Val accuracy 0.612\n",
            "Epoch 50/50: Training loss 0.023 , Val loss 0.023 , Training accuracy 0.611 , Val accuracy 0.612\n",
            "Best training accuracy is 0.6130902551700617\n",
            "Best val accuracy is 0.6137876157407407\n"
          ]
        }
      ],
      "source": [
        "model = AutoEncoder()\n",
        "batch_size = 64\n",
        "num_epochs = 50\n",
        "learning_rate = 0.001\n",
        "\n",
        "train(model, train_data, val_data, batch_size, num_epochs=num_epochs, learning_rate=learning_rate, plot = False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoEncoder()\n",
        "batch_size = 32\n",
        "num_epochs = 50\n",
        "learning_rate = 0.005\n",
        "\n",
        "train(model, train_data, val_data, batch_size, num_epochs=num_epochs, learning_rate=learning_rate, plot = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdwbQ8YBHm_N",
        "outputId": "d10299e6-8a69-4928-a579-a6da173b8a94"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50: Training loss 0.049 , Val loss 0.027 , Training accuracy 0.599 , Val accuracy 0.601\n",
            "best model saved\n",
            "checkpoint model saved\n",
            "Epoch 2/50: Training loss 0.025 , Val loss 0.023 , Training accuracy 0.576 , Val accuracy 0.578\n",
            "Epoch 3/50: Training loss 0.021 , Val loss 0.021 , Training accuracy 0.592 , Val accuracy 0.590\n",
            "Epoch 4/50: Training loss 0.020 , Val loss 0.019 , Training accuracy 0.606 , Val accuracy 0.605\n",
            "best model saved\n",
            "Epoch 5/50: Training loss 0.019 , Val loss 0.018 , Training accuracy 0.610 , Val accuracy 0.607\n",
            "best model saved\n",
            "Epoch     6: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch 6/50: Training loss 0.017 , Val loss 0.017 , Training accuracy 0.606 , Val accuracy 0.607\n",
            "Epoch 7/50: Training loss 0.016 , Val loss 0.016 , Training accuracy 0.623 , Val accuracy 0.622\n",
            "best model saved\n",
            "Epoch 8/50: Training loss 0.015 , Val loss 0.016 , Training accuracy 0.619 , Val accuracy 0.621\n",
            "Epoch 9/50: Training loss 0.015 , Val loss 0.015 , Training accuracy 0.615 , Val accuracy 0.616\n",
            "Epoch    10: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch 10/50: Training loss 0.015 , Val loss 0.015 , Training accuracy 0.629 , Val accuracy 0.633\n",
            "best model saved\n",
            "Epoch 11/50: Training loss 0.015 , Val loss 0.014 , Training accuracy 0.647 , Val accuracy 0.648\n",
            "best model saved\n",
            "checkpoint model saved\n",
            "Epoch 12/50: Training loss 0.014 , Val loss 0.015 , Training accuracy 0.645 , Val accuracy 0.647\n",
            "Epoch 13/50: Training loss 0.014 , Val loss 0.014 , Training accuracy 0.649 , Val accuracy 0.650\n",
            "best model saved\n",
            "Epoch    14: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch 14/50: Training loss 0.014 , Val loss 0.014 , Training accuracy 0.652 , Val accuracy 0.653\n",
            "best model saved\n",
            "Epoch 15/50: Training loss 0.014 , Val loss 0.014 , Training accuracy 0.654 , Val accuracy 0.655\n",
            "best model saved\n",
            "Epoch 16/50: Training loss 0.014 , Val loss 0.014 , Training accuracy 0.656 , Val accuracy 0.656\n",
            "best model saved\n",
            "Epoch 17/50: Training loss 0.014 , Val loss 0.014 , Training accuracy 0.656 , Val accuracy 0.657\n",
            "best model saved\n",
            "Epoch    18: reducing learning rate of group 0 to 3.1250e-04.\n",
            "Epoch 18/50: Training loss 0.014 , Val loss 0.013 , Training accuracy 0.666 , Val accuracy 0.665\n",
            "best model saved\n",
            "Epoch 19/50: Training loss 0.014 , Val loss 0.014 , Training accuracy 0.664 , Val accuracy 0.664\n",
            "Epoch 20/50: Training loss 0.013 , Val loss 0.013 , Training accuracy 0.666 , Val accuracy 0.667\n",
            "best model saved\n",
            "Epoch 21/50: Training loss 0.014 , Val loss 0.013 , Training accuracy 0.654 , Val accuracy 0.656\n",
            "checkpoint model saved\n",
            "Epoch    22: reducing learning rate of group 0 to 1.5625e-04.\n",
            "Epoch 22/50: Training loss 0.014 , Val loss 0.013 , Training accuracy 0.668 , Val accuracy 0.668\n",
            "best model saved\n",
            "Epoch 23/50: Training loss 0.013 , Val loss 0.013 , Training accuracy 0.668 , Val accuracy 0.668\n",
            "Epoch 24/50: Training loss 0.013 , Val loss 0.014 , Training accuracy 0.668 , Val accuracy 0.669\n",
            "best model saved\n",
            "Epoch 25/50: Training loss 0.013 , Val loss 0.014 , Training accuracy 0.668 , Val accuracy 0.668\n",
            "Epoch    26: reducing learning rate of group 0 to 7.8125e-05.\n",
            "Epoch 26/50: Training loss 0.013 , Val loss 0.013 , Training accuracy 0.668 , Val accuracy 0.669\n",
            "best model saved\n",
            "Epoch 27/50: Training loss 0.013 , Val loss 0.013 , Training accuracy 0.669 , Val accuracy 0.669\n",
            "best model saved\n",
            "Epoch 28/50: Training loss 0.014 , Val loss 0.014 , Training accuracy 0.670 , Val accuracy 0.670\n",
            "best model saved\n",
            "Epoch 29/50: Training loss 0.013 , Val loss 0.014 , Training accuracy 0.667 , Val accuracy 0.669\n",
            "Epoch    30: reducing learning rate of group 0 to 3.9063e-05.\n",
            "Epoch 30/50: Training loss 0.014 , Val loss 0.013 , Training accuracy 0.668 , Val accuracy 0.667\n",
            "Epoch 31/50: Training loss 0.013 , Val loss 0.013 , Training accuracy 0.670 , Val accuracy 0.670\n",
            "best model saved\n",
            "checkpoint model saved\n",
            "Epoch 32/50: Training loss 0.013 , Val loss 0.014 , Training accuracy 0.671 , Val accuracy 0.671\n",
            "best model saved\n",
            "Epoch 33/50: Training loss 0.014 , Val loss 0.013 , Training accuracy 0.670 , Val accuracy 0.670\n",
            "Epoch    34: reducing learning rate of group 0 to 1.9531e-05.\n",
            "Epoch 34/50: Training loss 0.013 , Val loss 0.014 , Training accuracy 0.671 , Val accuracy 0.672\n",
            "best model saved\n",
            "Epoch 35/50: Training loss 0.013 , Val loss 0.014 , Training accuracy 0.670 , Val accuracy 0.670\n",
            "Epoch 36/50: Training loss 0.013 , Val loss 0.014 , Training accuracy 0.670 , Val accuracy 0.671\n",
            "Epoch 37/50: Training loss 0.013 , Val loss 0.013 , Training accuracy 0.670 , Val accuracy 0.671\n",
            "Epoch    38: reducing learning rate of group 0 to 9.7656e-06.\n",
            "Epoch 38/50: Training loss 0.013 , Val loss 0.013 , Training accuracy 0.670 , Val accuracy 0.671\n",
            "Epoch 39/50: Training loss 0.013 , Val loss 0.013 , Training accuracy 0.670 , Val accuracy 0.671\n",
            "Epoch 40/50: Training loss 0.013 , Val loss 0.013 , Training accuracy 0.670 , Val accuracy 0.671\n",
            "Epoch 41/50: Training loss 0.013 , Val loss 0.013 , Training accuracy 0.671 , Val accuracy 0.671\n",
            "checkpoint model saved\n",
            "Epoch    42: reducing learning rate of group 0 to 4.8828e-06.\n",
            "Epoch 42/50: Training loss 0.013 , Val loss 0.013 , Training accuracy 0.671 , Val accuracy 0.671\n",
            "Epoch 43/50: Training loss 0.013 , Val loss 0.013 , Training accuracy 0.671 , Val accuracy 0.672\n",
            "best model saved\n",
            "Epoch 44/50: Training loss 0.013 , Val loss 0.013 , Training accuracy 0.671 , Val accuracy 0.672\n",
            "best model saved\n",
            "Epoch 45/50: Training loss 0.013 , Val loss 0.013 , Training accuracy 0.671 , Val accuracy 0.672\n",
            "best model saved\n",
            "Epoch    46: reducing learning rate of group 0 to 2.4414e-06.\n",
            "Epoch 46/50: Training loss 0.013 , Val loss 0.013 , Training accuracy 0.671 , Val accuracy 0.672\n",
            "Epoch 47/50: Training loss 0.013 , Val loss 0.013 , Training accuracy 0.671 , Val accuracy 0.672\n",
            "Epoch 48/50: Training loss 0.013 , Val loss 0.013 , Training accuracy 0.671 , Val accuracy 0.671\n",
            "Epoch 49/50: Training loss 0.013 , Val loss 0.013 , Training accuracy 0.671 , Val accuracy 0.672\n",
            "Epoch    50: reducing learning rate of group 0 to 1.2207e-06.\n",
            "Epoch 50/50: Training loss 0.013 , Val loss 0.013 , Training accuracy 0.671 , Val accuracy 0.672\n",
            "Best training accuracy is 0.6708910798995442\n",
            "Best val accuracy is 0.6720558449074074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoEncoder()\n",
        "batch_size = 64\n",
        "num_epochs = 50\n",
        "learning_rate = 0.005\n",
        "\n",
        "train(model, train_data, val_data, batch_size, num_epochs=num_epochs, learning_rate=learning_rate, plot = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G97k0l7bHqTx",
        "outputId": "976a685d-6807-4520-c498-b562ba54ab32"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50: Training loss 0.063 , Val loss 0.040 , Training accuracy 0.595 , Val accuracy 0.598\n",
            "best model saved\n",
            "checkpoint model saved\n",
            "Epoch 2/50: Training loss 0.032 , Val loss 0.027 , Training accuracy 0.581 , Val accuracy 0.583\n",
            "Epoch 3/50: Training loss 0.026 , Val loss 0.024 , Training accuracy 0.593 , Val accuracy 0.595\n",
            "Epoch 4/50: Training loss 0.023 , Val loss 0.022 , Training accuracy 0.593 , Val accuracy 0.594\n",
            "Epoch 5/50: Training loss 0.022 , Val loss 0.021 , Training accuracy 0.597 , Val accuracy 0.599\n",
            "best model saved\n",
            "Epoch     6: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch 6/50: Training loss 0.021 , Val loss 0.021 , Training accuracy 0.595 , Val accuracy 0.598\n",
            "Epoch 7/50: Training loss 0.020 , Val loss 0.019 , Training accuracy 0.611 , Val accuracy 0.613\n",
            "best model saved\n",
            "Epoch 8/50: Training loss 0.019 , Val loss 0.019 , Training accuracy 0.612 , Val accuracy 0.614\n",
            "best model saved\n",
            "Epoch 9/50: Training loss 0.019 , Val loss 0.018 , Training accuracy 0.613 , Val accuracy 0.617\n",
            "best model saved\n",
            "Epoch    10: reducing learning rate of group 0 to 1.2500e-03.\n",
            "Epoch 10/50: Training loss 0.019 , Val loss 0.018 , Training accuracy 0.616 , Val accuracy 0.618\n",
            "best model saved\n",
            "Epoch 11/50: Training loss 0.018 , Val loss 0.017 , Training accuracy 0.619 , Val accuracy 0.621\n",
            "best model saved\n",
            "checkpoint model saved\n",
            "Epoch 12/50: Training loss 0.018 , Val loss 0.018 , Training accuracy 0.620 , Val accuracy 0.623\n",
            "best model saved\n",
            "Epoch 13/50: Training loss 0.017 , Val loss 0.017 , Training accuracy 0.619 , Val accuracy 0.621\n",
            "Epoch    14: reducing learning rate of group 0 to 6.2500e-04.\n",
            "Epoch 14/50: Training loss 0.017 , Val loss 0.018 , Training accuracy 0.620 , Val accuracy 0.623\n",
            "best model saved\n",
            "Epoch 15/50: Training loss 0.017 , Val loss 0.016 , Training accuracy 0.620 , Val accuracy 0.622\n",
            "Epoch 16/50: Training loss 0.017 , Val loss 0.017 , Training accuracy 0.621 , Val accuracy 0.624\n",
            "best model saved\n",
            "Epoch 17/50: Training loss 0.017 , Val loss 0.017 , Training accuracy 0.626 , Val accuracy 0.628\n",
            "best model saved\n",
            "Epoch    18: reducing learning rate of group 0 to 3.1250e-04.\n",
            "Epoch 18/50: Training loss 0.017 , Val loss 0.017 , Training accuracy 0.626 , Val accuracy 0.629\n",
            "best model saved\n",
            "Epoch 19/50: Training loss 0.017 , Val loss 0.016 , Training accuracy 0.628 , Val accuracy 0.631\n",
            "best model saved\n",
            "Epoch 20/50: Training loss 0.017 , Val loss 0.017 , Training accuracy 0.629 , Val accuracy 0.631\n",
            "best model saved\n",
            "Epoch 21/50: Training loss 0.017 , Val loss 0.017 , Training accuracy 0.627 , Val accuracy 0.629\n",
            "checkpoint model saved\n",
            "Epoch    22: reducing learning rate of group 0 to 1.5625e-04.\n",
            "Epoch 22/50: Training loss 0.017 , Val loss 0.016 , Training accuracy 0.627 , Val accuracy 0.628\n",
            "Epoch 23/50: Training loss 0.017 , Val loss 0.017 , Training accuracy 0.629 , Val accuracy 0.631\n",
            "Epoch 24/50: Training loss 0.016 , Val loss 0.017 , Training accuracy 0.629 , Val accuracy 0.630\n",
            "Epoch 25/50: Training loss 0.016 , Val loss 0.017 , Training accuracy 0.630 , Val accuracy 0.631\n",
            "best model saved\n",
            "Epoch    26: reducing learning rate of group 0 to 7.8125e-05.\n",
            "Epoch 26/50: Training loss 0.016 , Val loss 0.017 , Training accuracy 0.630 , Val accuracy 0.633\n",
            "best model saved\n",
            "Epoch 27/50: Training loss 0.017 , Val loss 0.016 , Training accuracy 0.631 , Val accuracy 0.633\n",
            "best model saved\n",
            "Epoch 28/50: Training loss 0.017 , Val loss 0.016 , Training accuracy 0.631 , Val accuracy 0.633\n",
            "best model saved\n",
            "Epoch 29/50: Training loss 0.016 , Val loss 0.017 , Training accuracy 0.632 , Val accuracy 0.633\n",
            "Epoch    30: reducing learning rate of group 0 to 3.9063e-05.\n",
            "Epoch 30/50: Training loss 0.017 , Val loss 0.017 , Training accuracy 0.630 , Val accuracy 0.632\n",
            "Epoch 31/50: Training loss 0.016 , Val loss 0.016 , Training accuracy 0.631 , Val accuracy 0.632\n",
            "checkpoint model saved\n",
            "Epoch 32/50: Training loss 0.017 , Val loss 0.016 , Training accuracy 0.631 , Val accuracy 0.632\n",
            "Epoch 33/50: Training loss 0.016 , Val loss 0.016 , Training accuracy 0.630 , Val accuracy 0.631\n",
            "Epoch    34: reducing learning rate of group 0 to 1.9531e-05.\n",
            "Epoch 34/50: Training loss 0.016 , Val loss 0.017 , Training accuracy 0.631 , Val accuracy 0.633\n",
            "Epoch 35/50: Training loss 0.017 , Val loss 0.017 , Training accuracy 0.631 , Val accuracy 0.633\n",
            "Epoch 36/50: Training loss 0.016 , Val loss 0.016 , Training accuracy 0.631 , Val accuracy 0.633\n",
            "Epoch 37/50: Training loss 0.016 , Val loss 0.017 , Training accuracy 0.631 , Val accuracy 0.634\n",
            "best model saved\n",
            "Epoch    38: reducing learning rate of group 0 to 9.7656e-06.\n",
            "Epoch 38/50: Training loss 0.016 , Val loss 0.016 , Training accuracy 0.631 , Val accuracy 0.633\n",
            "Epoch 39/50: Training loss 0.016 , Val loss 0.017 , Training accuracy 0.631 , Val accuracy 0.632\n",
            "Epoch 40/50: Training loss 0.016 , Val loss 0.016 , Training accuracy 0.631 , Val accuracy 0.633\n",
            "Epoch 41/50: Training loss 0.016 , Val loss 0.016 , Training accuracy 0.631 , Val accuracy 0.633\n",
            "checkpoint model saved\n",
            "Epoch    42: reducing learning rate of group 0 to 4.8828e-06.\n",
            "Epoch 42/50: Training loss 0.016 , Val loss 0.017 , Training accuracy 0.631 , Val accuracy 0.632\n",
            "Epoch 43/50: Training loss 0.016 , Val loss 0.016 , Training accuracy 0.632 , Val accuracy 0.633\n",
            "Epoch 44/50: Training loss 0.016 , Val loss 0.017 , Training accuracy 0.632 , Val accuracy 0.633\n",
            "Epoch 45/50: Training loss 0.016 , Val loss 0.016 , Training accuracy 0.631 , Val accuracy 0.633\n",
            "Epoch    46: reducing learning rate of group 0 to 2.4414e-06.\n",
            "Epoch 46/50: Training loss 0.017 , Val loss 0.017 , Training accuracy 0.631 , Val accuracy 0.633\n",
            "Epoch 47/50: Training loss 0.017 , Val loss 0.017 , Training accuracy 0.631 , Val accuracy 0.633\n",
            "Epoch 48/50: Training loss 0.016 , Val loss 0.017 , Training accuracy 0.631 , Val accuracy 0.633\n",
            "Epoch 49/50: Training loss 0.016 , Val loss 0.017 , Training accuracy 0.632 , Val accuracy 0.633\n",
            "Epoch    50: reducing learning rate of group 0 to 1.2207e-06.\n",
            "Epoch 50/50: Training loss 0.016 , Val loss 0.017 , Training accuracy 0.631 , Val accuracy 0.633\n",
            "Best training accuracy is 0.6317474343471925\n",
            "Best val accuracy is 0.6335358796296297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymCsZH291prI"
      },
      "source": [
        "## Part 4. Testing [12 pt]\n",
        "\n",
        "### Part (a) [2 pt]\n",
        "\n",
        "Compute and report the test accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given that the best performance is achieved with batch size of 32 and learning rate of 0.005, we use the best model from there."
      ],
      "metadata": {
        "id": "i2kgMHuZKqp7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0OkSbup91prJ",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "2ccc8ebd-2a8c-47c7-feb0-41ffcb8ffd34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The test accuracy is 67.19%\n"
          ]
        }
      ],
      "source": [
        "model = AutoEncoder()\n",
        "model.load_state_dict(torch.load(\"/content/backup/model_AutoEncoder_bs32_lr0.005_epochs50/best.pth\"))\n",
        "\n",
        "test_loader= torch.utils.data.DataLoader(test_data, batch_size= 1, shuffle= True)\n",
        "\n",
        "test_acc= get_accuracy(model, test_loader)\n",
        "\n",
        "print(f'The test accuracy is {(test_acc * 100):.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEe9yt6L1prM"
      },
      "source": [
        "### Part (b) [4 pt]\n",
        "\n",
        "Based on the test accuracy alone, it is difficult to assess whether our model\n",
        "is actually performing well. We don't know whether a high accuracy is due to\n",
        "the simplicity of the problem, or if a poor accuracy is a result of the inherent\n",
        "difficulty of the problem.\n",
        "\n",
        "It is therefore very important to be able to compare our model to at least one\n",
        "alternative. In particular, we consider a simple **baseline**\n",
        "model that is not very computationally expensive. Our neural network\n",
        "should at least outperform this baseline model. If our network is not much\n",
        "better than the baseline, then it is not doing well.\n",
        "\n",
        "For our data imputation problem, consider the following baseline model:\n",
        "to predict a missing feature, the baseline model will look at the **most common value** of the feature in the training set. \n",
        "\n",
        "For example, if the feature \"marriage\" is missing, then this model's prediction will be the most common value for \"marriage\" in the training set, which happens to be \"Married-civ-spouse\".\n",
        "\n",
        "What would be the test accuracy of this baseline model?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "p45VHp011prN",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "8eb4775b-386d-4e0a-d76b-cbbc86286c02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for category age is 2.85%\n",
            "Accuracy for category yredu is 32.45%\n",
            "Accuracy for category capgain is 91.57%\n",
            "Accuracy for category caploss is 95.24%\n",
            "Accuracy for category workhr is 47.28%\n",
            "Accuracy for category work is 73.89%\n",
            "Accuracy for category marriage is 46.68%\n",
            "Accuracy for category occupation is 13.48%\n",
            "Accuracy for category edu is 32.45%\n",
            "Accuracy for category relationship is 41.36%\n",
            "Accuracy for category sex is 67.67%\n",
            "The accuracy for baseline model is 49.54%\n"
          ]
        }
      ],
      "source": [
        "mode = {}\n",
        "accuracy = 0.0\n",
        "\n",
        "for col in df_not_missing.columns:\n",
        "  mode[col] = df_not_missing[col].mode()[0] # get the most common value for each column\n",
        "  accuracy_col = sum(df_not_missing[col] == mode[col])/len(df_not_missing)\n",
        "  print (f\"Accuracy for category {col} is {accuracy_col*100:.2f}%\")\n",
        "  accuracy += accuracy_col\n",
        "print(f\"The accuracy for baseline model is {accuracy*100/len(df_not_missing.columns):.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlHu0wxh1prP"
      },
      "source": [
        "### Part (c) [1 pt]\n",
        "\n",
        "How does your test accuracy from part (a) compared to your basline test accuracy in part (b)?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy in part(a) is much better than part(b). This could be because our Neural Net learns to predict based on the features presented, whereas the baseline just uses the mode of the column. However, it could be that our dataset is skewed towards certain values and the autoencoder is predicting only for some categories but not for others as some columns do see a high accuracy by using the mode value."
      ],
      "metadata": {
        "id": "W4Jimhu5N_EQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfQPgu1Q1prS"
      },
      "source": [
        "### Part (d) [1 pt]\n",
        "\n",
        "Look at the first item in your test data. \n",
        "Do you think it is reasonable for a human\n",
        "to be able to guess this person's education level\n",
        "based on their other features? Explain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3qbQ1vvT1prT",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "a633700d-c57a-4bbf-d326-60694dac7edb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'edu': '11th',\n",
              " 'marriage': 'Divorced',\n",
              " 'occupation': 'Other-service',\n",
              " 'relationship': 'Unmarried',\n",
              " 'sex': 'Female',\n",
              " 'work': 'Private'}"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ],
      "source": [
        "get_features(test_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A human may not be able to guess this person's education level, as this is a very generic profile that does not disclose much. A common guess for edu would be high school or bachelor's, but not 11th. "
      ],
      "metadata": {
        "id": "iajlcq53PZQl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_d5uuAY1prZ"
      },
      "source": [
        "### Part (e) [2 pt]\n",
        "\n",
        "What is your model's prediction of this person's education\n",
        "level, given their other features?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kBY5gKXR1pra",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "a5551b13-a973-4ebe-f094-7bf17bb73739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HS-grad\n"
          ]
        }
      ],
      "source": [
        "#the model is already loaded from testing.\n",
        "single_test_data = test_data[0]\n",
        "single_test_data[cat_index['edu']:cat_index['edu'] + len(cat_values['edu'])] = 0\n",
        "single_test_data = torch.from_numpy(single_test_data).to(device)  \n",
        "pred = model(single_test_data)\n",
        "pred = pred.detach().cpu().numpy()\n",
        "pred_edu = get_feature(pred, \"edu\")\n",
        "print(pred_edu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdLNA0ce1prd"
      },
      "source": [
        "### Part (f) [2 pt]\n",
        "\n",
        "What is the baseline model's prediction\n",
        "of this person's education level?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TXgoM9qk1prd",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "6bcd3d39-7399-4780-d172-b062eeacc8ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " HS-grad\n"
          ]
        }
      ],
      "source": [
        "print(mode['edu'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "HwjDg1uM1pqe",
        "OEJ0Ci3l1pqh",
        "1_5ZZR_J1pqy",
        "WKk01pwx1pq_",
        "SxCTlXoV1prB",
        "h9xTwIf51prF",
        "UEe9yt6L1prM",
        "QlHu0wxh1prP",
        "DfQPgu1Q1prS",
        "p_d5uuAY1prZ",
        "fdLNA0ce1prd"
      ],
      "name": "Lab_4_Data_Imputation_Winter_2022.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
